<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Realtime Voice</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body{font-family:system-ui;margin:2rem;max-width:800px}
    button{padding:.6rem 1rem;margin:.25rem .5rem .25rem 0}
    pre{background:#f6f6f6;padding:1rem;border-radius:.5rem;white-space:pre-wrap}
    .status{font-size:.95rem;margin:.5rem 0}
    .ok{color:#0a7b22}
    .error{color:#b00020}
    .listen{color:#b00020;font-weight:bold}
    .speak{color:#0066cc;font-weight:bold}
    .muted{opacity:.6}
  </style>
</head>
<body>
  <h1>Realtime Voice</h1>
  <p>Click Start to grant mic access. Speak any time ‚Äî TTS will stop instantly when you talk.</p>

  <div>
    <button id="start">üéôÔ∏è Start</button>
    <button id="stop"  disabled>‚èπÔ∏è Stop</button>
    <button id="echo"  class="muted" title="Quick WS routing test">üîé Test Echo</button>
  </div>
  <div class="status" id="status">Idle</div>

  <p><strong>Partial:</strong> <span id="partial"></span></p>
  <pre id="final"></pre>

<script>
/* =========================
   URLs & globals
========================= */
const WS_PATH  = '/ws/stream';
const ECHO_PATH= '/ws/echo';
const WS_URL   = (location.protocol==='https:'?'wss://':'ws://') + location.host + WS_PATH;
const ECHO_URL = (location.protocol==='https:'?'wss://':'ws://') + location.host + ECHO_PATH;

let ws, wsRetry=0, pingTimer=null;
let audioCtx=null, micNode=null, stream=null, running=false;

// ==== TTS (AudioWorklet) ====
let ttsCtx=null, ttsNode=null, ttsSrcRate=24000;

/* =========================
   Helpers
========================= */
const $ = id => document.getElementById(id);
function setStatus(text, cls=""){ const el=$('status'); el.textContent=text; el.className="status "+cls; }

// base64 PCM16LE -> Float32 [-1,1]
function base64ToFloat32(b64) {
  const bin = atob(b64);
  const bytes = new Uint8Array(bin.length);
  for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
  const view = new DataView(bytes.buffer);
  const out = new Float32Array(bytes.byteLength / 2);
  for (let i = 0, j = 0; i < bytes.byteLength; i += 2, j++) {
    const s = view.getInt16(i, true); // little-endian
    out[j] = s / 32768;
  }
  return out;
}
// simple linear resampler (srcRate -> dstRate)
function resampleLinear(f32, srcRate, dstRate){
  if (srcRate === dstRate) return f32;
  const ratio = dstRate / srcRate;
  const out = new Float32Array(Math.floor(f32.length * ratio));
  let pos = 0;
  for (let i = 0; i < out.length; i++) {
    const idx = pos | 0, frac = pos - idx;
    const a = f32[idx] || 0, b = f32[idx+1] || a;
    out[i] = a + (b - a) * frac;
    pos += 1 / ratio;
  }
  return out;
}
function toB64(u8){ let s=""; for(let i=0;i<u8.length;i++) s+=String.fromCharCode(u8[i]); return btoa(s); }
function f32ToI16(f){ const o=new Int16Array(f.length); for(let i=0;i<f.length;i++){ let s=Math.max(-1,Math.min(1,f[i])); o[i]=s<0?s*0x8000:s*0x7FFF; } return o; }
function downsample(buf,inRate,outRate=16000){
  if(inRate===outRate) return buf;
  const ratio=inRate/outRate, outLen=Math.floor(buf.length/ratio);
  const out=new Float32Array(outLen); let pos=0;
  for(let i=0;i<outLen;i++){ out[i]=buf[Math.floor(pos)]; pos+=ratio; }
  return out;
}

/* =========================
   TTS via AudioWorkletNode
========================= */
async function ensureTTSContext(sampleRateHint=24000){
  if (ttsCtx && ttsNode) return;
  // Try to hint device to 24k; many devices will still choose 44.1/48k.
  ttsCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: sampleRateHint });
  await ttsCtx.audioWorklet.addModule('/pcm-player-processor.js'); // <-- your file
  ttsNode = new AudioWorkletNode(ttsCtx, 'pcm-player');
  ttsNode.connect(ttsCtx.destination);
}
function ttsFlush(){
  try { ttsNode?.port.postMessage({ type: 'flush' }); } catch {}
}
function ttsStop(){
  try { ttsNode?.disconnect(); } catch {}
  try { ttsCtx?.close(); } catch {}
  ttsNode=null; ttsCtx=null;
}

/* =========================
   WebSocket lifecycle
========================= */
function attachWS(socket){
  console.log("WS_URL =", WS_URL);
  socket.onopen = ()=>{
    setStatus("WebSocket connected ‚úî","ok");
    wsRetry=0;
    // keepalive (some proxies idle-drop)
    pingTimer = setInterval(()=>{ 
      if(socket.readyState===WebSocket.OPEN) {
        try { socket.send(JSON.stringify({type:"ping", t:Date.now()})); } catch {}
      }
    }, 20000);
  };
  socket.onerror = (e)=>{ console.error("[WS] error", e); setStatus("WebSocket error","error"); };
  socket.onclose = (e)=>{
    console.warn("[WS] close", e.code, e.reason);
    setStatus(`WebSocket closed (${e.code})`,"error");
    if (pingTimer) { clearInterval(pingTimer); pingTimer=null; }
    if (running) {
      const backoff = Math.min(1000 * Math.pow(2, wsRetry++), 10000);
      setTimeout(() => { connectWS(); }, backoff);
    }
  };
  socket.onmessage = async (evt)=>{
    const m = JSON.parse(evt.data);

    if(m.type==="partial"){ $('partial').textContent = m.text; }
    if(m.type==="final"){
      $('partial').textContent = "";
      $('final').textContent = `You: ${m.text}\nAssistant: ${m.reply}`;
    }

    // ====== TTS handling (no ScriptProcessorNode) ======
    if(m.type==="tts_start"){
      ttsSrcRate = m.sample_rate || 24000;
      await ensureTTSContext(ttsSrcRate);
      if (ttsCtx.state === 'suspended') { try { await ttsCtx.resume(); } catch {} }
      setStatus("Speaking‚Ä¶","speak");
    }
    if(m.type==="tts_chunk" && ttsNode){
      // decode PCM16 b64 -> float32 @ source rate, resample to output ctx rate, then post to worklet
      const f32src = base64ToFloat32(m.pcm_b64);
      const f32out = resampleLinear(f32src, ttsSrcRate, ttsCtx.sampleRate);
      ttsNode.port.postMessage({ type: 'audio', samples: f32out }, [f32out.buffer]);
    }
    if(m.type==="tts_end"){
      ttsFlush();
      setStatus("Listening‚Ä¶","listen");
    }
    if(m.type==="tts_stop" || (m.type==="event" && m.name==="speech_started")){
      ttsFlush();
      setStatus("Listening‚Ä¶","listen");
    }
  };
}
function connectWS(){
  ws = new WebSocket(WS_URL);
  attachWS(ws);
}

/* =========================
   Mic ‚Üí frames ‚Üí WS
   (Still ScriptProcessor; can upgrade to Worklet later)
========================= */
async function start(){
  if(running) return; running=true;
  setStatus("Connecting‚Ä¶");

  // 1) Ensure WS is open
  connectWS();
  try{
    await new Promise((res,rej)=>{
      if (ws.readyState===WebSocket.OPEN) return res();
      const t=setTimeout(()=>{ cleanup(); rej(new Error("WS open timeout")); }, 10000);
      const onOpen=()=>{ cleanup(); res(); };
      const onErr =(e)=>{ cleanup(); rej(e); };
      const onCls =(e)=>{ cleanup(); rej(e); };
      function cleanup(){ clearTimeout(t); ws.removeEventListener('open',onOpen); ws.removeEventListener('error',onErr); ws.removeEventListener('close',onCls); }
      ws.addEventListener('open',onOpen); ws.addEventListener('error',onErr); ws.addEventListener('close',onCls);
    });
  } catch (e) {
    setStatus("WS failed to open","error"); running=false; return;
  }

  // 2) Get mic
  try { stream = await navigator.mediaDevices.getUserMedia({ audio: true }); }
  catch (e) { console.error(e); setStatus("Mic permission denied","error"); running=false; return; }

  // 3) AudioContext and capture
  audioCtx = new (window.AudioContext||window.webkitAudioContext)({ sampleRate:48000 });
  if (audioCtx.state==='suspended') { try{ await audioCtx.resume(); }catch{} }

  const srcNode = audioCtx.createMediaStreamSource(stream);

  // NOTE: still using ScriptProcessor here; we can swap to an AudioWorklet later if you want.
  const proc = audioCtx.createScriptProcessor(1024,1,1);
  proc.onaudioprocess = (e)=>{
    if(!ws || ws.readyState!==WebSocket.OPEN) return;
    const input = e.inputBuffer.getChannelData(0);
    const ds = downsample(input, audioCtx.sampleRate, 16000);
    const i16 = f32ToI16(ds);
    try {
      ws.send(JSON.stringify({ type:"audio", audio_b64: toB64(new Uint8Array(i16.buffer)) }));
    } catch {}
  };
  srcNode.connect(proc); proc.connect(audioCtx.destination);
  micNode = proc;

  $('start').disabled = true; $('stop').disabled = false;
  setStatus("Listening‚Ä¶","listen");
}

function stop(){
  running=false;
  try{ ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"barge_in"})); }catch{}
  try{ micNode && micNode.disconnect(); }catch{}
  try{ stream && stream.getTracks().forEach(t=>t.stop()); }catch{}
  try{ audioCtx && audioCtx.close(); }catch{}
  try{ ws && ws.close(); }catch{}
  if (pingTimer) { clearInterval(pingTimer); pingTimer=null; }
  ttsStop();
  $('start').disabled = false; $('stop').disabled = true;
  setStatus("Stopped.");
}

/* =========================
   Quick WS echo test
========================= */
$('echo').onclick = ()=>{
  const t = new WebSocket(ECHO_URL);
  t.onopen  = ()=>console.log('[ECHO] open');
  t.onerror = (e)=>console.error('[ECHO] error', e);
  t.onclose = (e)=>console.warn('[ECHO] close', e.code, e.reason);
  t.onmessage=(e)=>console.log('[ECHO] msg', e.data);
  setTimeout(()=>{ try{ t.readyState===WebSocket.OPEN && t.send('hello'); }catch{} }, 500);
};

$('start').onclick = start;
$('stop').onclick  = stop;
window.addEventListener('beforeunload', ()=>{ try{ ws && ws.close(); }catch{} });
</script>
</body>
</html>
