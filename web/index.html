<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Realtime Voice</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body{font-family:system-ui;margin:2rem;max-width:800px}
    button{padding:.6rem 1rem;margin:.25rem .5rem .25rem 0}
    pre{background:#f6f6f6;padding:1rem;border-radius:.5rem;white-space:pre-wrap}
    .status{font-size:.95rem;margin:.5rem 0}
    .ok{color:#0a7b22}
    .error{color:#b00020}
    .listen{color:#b00020;font-weight:bold}
    .speak{color:#0066cc;font-weight:bold}
    .muted{opacity:.6}
    #meter{width:220px;height:6px;background:#eee;border-radius:3px;overflow:hidden;margin:.4rem 0}
    #bar{height:100%;width:0;background:#0a7b22;transition:width .05s linear}
    #log{white-space:pre-wrap;background:#fafafa;border:1px solid #eee;border-radius:6px;padding:8px;max-height:220px;overflow:auto}
  </style>
</head>
<body>
  <h1>Realtime Voice</h1>
  <p>Click Start to grant mic access. Speak any time â€” TTS will stop instantly when you talk.</p>

  <div>
    <button id="start">ğŸ™ï¸ Start</button>
    <button id="stop"  disabled>â¹ï¸ Stop</button>
    <button id="force" title="Force commit current turn" class="muted">ğŸš€ Force Send</button>
    <button id="echo"  class="muted" title="Quick WS routing test">ğŸ” Test Echo</button>
  </div>

  <div class="status" id="status">Idle</div>
  <div id="meter"><div id="bar"></div></div>

  <p><strong>Partial:</strong> <span id="partial"></span></p>
  <pre id="final"></pre>

  <h3>Logs</h3>
  <pre id="log"></pre>

<script>
/* =========================
   URLs & globals
========================= */
const WS_PATH  = '/ws/stream';
const ECHO_PATH= '/ws/echo';
const WS_URL   = (location.protocol==='https:'?'wss://':'ws://') + location.host + WS_PATH;
const ECHO_URL = (location.protocol==='https:'?'wss://':'ws://') + location.host + ECHO_PATH;

let ws, wsRetry=0, pingTimer=null;
let audioCtx=null, stream=null, running=false;
let micNode=null, micSink=null;

// ==== TTS (AudioWorklet) ====
let ttsCtx=null, ttsNode=null, ttsSrcRate=24000;
let ttsPlaying=false;           // are we currently talking?
let ttsBarged=false;            // have we sent barge_in during this speech burst?

/* =========================
   Helpers
========================= */
const $ = id => document.getElementById(id);
const log = (...a)=>{ try{ console.log(...a); }catch(e){}; const el=$('log'); el.textContent += a.join(' ') + '\n'; el.scrollTop = el.scrollHeight; };
function setStatus(text, cls=""){ const el=$('status'); el.textContent=text; el.className="status "+cls; }

// base64 PCM16LE -> Float32 [-1,1]
function base64ToFloat32(b64) {
  const bin = atob(b64);
  const bytes = new Uint8Array(bin.length);
  for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
  const view = new DataView(bytes.buffer);
  const out = new Float32Array(bytes.byteLength / 2);
  for (let i = 0, j = 0; i < bytes.byteLength; i += 2, j++) {
    const s = view.getInt16(i, true);
    out[j] = s / 32768;
  }
  return out;
}
function resampleLinear(f32, srcRate, dstRate){
  if (srcRate === dstRate) return f32;
  const ratio = dstRate / srcRate;
  const out = new Float32Array(Math.floor(f32.length * ratio));
  let pos = 0;
  for (let i = 0; i < out.length; i++) {
    const idx = pos | 0, frac = pos - idx;
    const a = f32[idx] || 0, b = f32[idx+1] || a;
    out[i] = a + (b - a) * frac;
    pos += 1 / ratio;
  }
  return out;
}
function toB64(u8){ let s=""; for(let i=0;i<u8.length;i++) s+=String.fromCharCode(u8[i]); return btoa(s); }
function f32ToI16(f){ const o=new Int16Array(f.length); for(let i=0;i<f.length;i++){ let s=Math.max(-1,Math.min(1,f[i])); o[i]=s<0? Math.round(s*0x8000) : Math.round(s*0x7FFF); } return o; }
function setMeter(level01){ $('bar').style.width = Math.min(1,Math.max(0,level01))*220 + 'px'; }
function rms(samples){ let s=0; for(let i=0;i<samples.length;i++){ const v=samples[i]; s+=v*v; } return Math.sqrt(s/Math.max(1,samples.length)); }

/* =========================
   TTS via AudioWorkletNode
========================= */
async function ensureTTSContext(sampleRateHint=24000){
  if (ttsCtx && ttsNode) return;
  ttsCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: sampleRateHint });
  await ttsCtx.audioWorklet.addModule('/pcm-player-processor.js'); // make sure this file is served
  ttsNode = new AudioWorkletNode(ttsCtx, 'pcm-player');
  ttsNode.connect(ttsCtx.destination);
}
function ttsFlush(){
  try { ttsNode?.port?.postMessage({ type: 'flush' }); } catch {}
}
function ttsStopLocal(){
  // Instant local stop
  ttsFlush();
  try { if (ttsCtx?.state === 'running') ttsCtx.suspend(); } catch {}
  ttsPlaying=false;
}

/* =========================
   Partial/final + VAD
========================= */
const VAD_THRESHOLD     = 0.012;  // raise to 0.015â€“0.02 if noisy
const VAD_SILENCE_MS    = 700;
const FINAL_FALLBACK_MS = 1400;
const NO_VAD_MAX_MS     = 1800;

let partialBuf = "";
let lastPartialAt = 0;
let lastEnergyAt  = 0;

let finalFallbackTimer = null;
let noVadTimer        = null;
let wasSpeaking       = false;
let silenceMs         = 0;
let lastFrameT        = performance.now();

/* =========================
   WebSocket lifecycle
========================= */
function attachWS(socket){
  log("WS_URL =", WS_URL);
  socket.onopen = ()=>{
    setStatus("WebSocket connected âœ”","ok");
    wsRetry=0;
    pingTimer = setInterval(()=>{
      if(socket.readyState===WebSocket.OPEN) {
        try { socket.send(JSON.stringify({type:"ping", t:Date.now()})); } catch {}
      }
    }, 20000);
  };
  socket.onerror = (e)=>{ console.error("[WS] error", e); setStatus("WebSocket error","error"); };
  socket.onclose = (e)=>{
    console.warn("[WS] close", e.code, e.reason);
    setStatus("WebSocket closed ("+e.code+")","error");
    if (pingTimer) { clearInterval(pingTimer); pingTimer=null; }
    if (running) {
      const backoff = Math.min(1000 * Math.pow(2, wsRetry++), 10000);
      setTimeout(() => { connectWS(); }, backoff);
    }
  };
  socket.onmessage = async (evt)=>{
    const m = JSON.parse(evt.data);

    if (m.type === "ack") log("ACK:", m.kind, m.bytes+"B");
    if (m.type === "error") log("UPSTREAM ERROR:", JSON.stringify(m.detail));
    if (m.type === "status") log("Upstream:", m.upstream);

    if (m.type === "event" && m.name === "speech_started") {
      // server VAD started â€” also stop TTS locally (belt & suspenders)
      ttsStopLocal();
      ttsBarged = true; // we've already barged this turn
    }

    if (m.type === "partial") {
      partialBuf += m.text || "";
      $('partial').textContent = partialBuf;
      lastPartialAt = performance.now();
      if (finalFallbackTimer) clearTimeout(finalFallbackTimer);
      finalFallbackTimer = setTimeout(()=>{
        try { ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"flush"})); } catch {}
      }, FINAL_FALLBACK_MS);
    }

    if (m.type === "final") {
      $('partial').textContent = "";
      const you = m.text && m.text.length ? m.text : partialBuf;
      $('final').textContent = "You: " + (you || "") + "\nAssistant: " + (m.reply || "");
      partialBuf = "";
      if (finalFallbackTimer) { clearTimeout(finalFallbackTimer); finalFallbackTimer=null; }
      if (noVadTimer)        { clearTimeout(noVadTimer);        noVadTimer=null; }
      setStatus("Listeningâ€¦","listen");
      // allow TTS again next turn
      ttsBarged = false;
    }

    // ====== TTS handling ======
    if(m.type==="tts_start"){
      ttsSrcRate = m.sample_rate || 24000;
      await ensureTTSContext(ttsSrcRate);
      if (ttsCtx.state === 'suspended') { try { await ttsCtx.resume(); } catch {} }
      ttsPlaying=true;
      setStatus("Speakingâ€¦","speak");
    }
    if(m.type==="tts_chunk" && ttsNode){
      // low-latency: push chunks as they arrive
      const f32src = base64ToFloat32(m.pcm_b64);
      const f32out = resampleLinear(f32src, ttsSrcRate, ttsCtx.sampleRate);
      ttsNode.port.postMessage({ type: 'audio', samples: f32out }, [f32out.buffer]);
    }
    if(m.type==="tts_end"){
      ttsPlaying=false;
      ttsFlush();
      setStatus("Listeningâ€¦","listen");
    }
    if(m.type==="tts_stop" || (m.type==="event" && m.name==="speech_started")){
      ttsStopLocal();
      setStatus("Listeningâ€¦","listen");
    }
  };
}
function connectWS(){ ws = new WebSocket(WS_URL); attachWS(ws); }

/* =========================
   Mic â†’ AudioWorklet â†’ WS
========================= */
async function start(){
  if(running) return; running=true;
  setStatus("Connectingâ€¦");

  connectWS();
  try{
    await new Promise((res,rej)=>{
      if (ws.readyState===WebSocket.OPEN) return res();
      const t=setTimeout(()=>{ cleanup(); rej(new Error("WS open timeout")); }, 10000);
      const onOpen=()=>{ cleanup(); res(); };
      const onErr =(e)=>{ cleanup(); rej(e); };
      const onCls =(e)=>{ cleanup(); rej(e); };
      function cleanup(){ clearTimeout(t); ws.removeEventListener('open',onOpen); ws.removeEventListener('error',onErr); ws.removeEventListener('close',onCls); }
      ws.addEventListener('open',onOpen); ws.addEventListener('error',onErr); ws.addEventListener('close',onCls);
    });
  } catch (e) { setStatus("WS failed to open","error"); running=false; return; }

  // 2) Mic permission
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      audio: { channelCount: 1, echoCancellation: true, noiseSuppression: true, autoGainControl: true }
    });
    log('Mic stream granted');
  } catch (e) { console.error(e); setStatus("Mic permission denied","error"); running=false; return; }

  // 3) AudioContext + Worklet
  audioCtx = new (window.AudioContext||window.webkitAudioContext)({ sampleRate:48000 });
  log('AudioContext rate =', audioCtx.sampleRate);
  if (audioCtx.state==='suspended') { try{ await audioCtx.resume(); } catch {} }
  try {
    await audioCtx.audioWorklet.addModule('/mic-capture-processor.js');
  } catch (e) {
    console.error('Failed to load /mic-capture-processor.js', e);
    setStatus('Failed to load mic worklet','error'); running=false; return;
  }

  const srcNode = audioCtx.createMediaStreamSource(stream);
  const micNodeLocal = new AudioWorkletNode(audioCtx, 'mic-capture-v2', {
    numberOfInputs: 1,
    numberOfOutputs: 1,
    outputChannelCount: [1],
    processorOptions: { downsampleTo: 16000, postIntervalMs: 20 } // 20ms -> 320 samples
  });

  let framesSent = 0;

  micNodeLocal.port.onmessage = (e)=>{
    const { type, samples, rate, frame_len } = e.data || {};

    if (type === 'debug') { if (rate) log('Worklet rate =', rate, 'frame_len =', frame_len); return; }

    if (type === 'audio' && ws && ws.readyState === WebSocket.OPEN) {
      const level = rms(samples);
      setMeter(level * 1.8);

      // ---- Local barge-in: STOP TTS *immediately* when you start talking
      if (level > VAD_THRESHOLD && ttsPlaying && !ttsBarged) {
        ttsStopLocal();                  // kill local playback now
        try { ws.send(JSON.stringify({ type: "barge_in" })); } catch {}
        ttsBarged = true;
      }

      // ---- Client-side silence â†’ force finalize (for reliability)
      const now = performance.now();
      const dt  = Math.max(0, now - lastFrameT);
      lastFrameT = now;

      if (level > VAD_THRESHOLD) {
        if (!wasSpeaking) {
          if (noVadTimer) clearTimeout(noVadTimer);
          noVadTimer = setTimeout(()=>{
            try { ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"flush"})); } catch {}
          }, NO_VAD_MAX_MS);
        }
        wasSpeaking = true;
        silenceMs = 0;
        lastEnergyAt = now;
      } else if (wasSpeaking) {
        silenceMs += dt;
        if (silenceMs >= VAD_SILENCE_MS) {
          try { ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"flush"})); } catch {}
          wasSpeaking = false;
          silenceMs = 0;
        }
      }

      // --- send audio frame ---
      const i16 = f32ToI16(samples);
      try {
        ws.send(JSON.stringify({
          type: "audio",
          sr: 16000,
          channels: 1,
          frame_samples: samples.length,
          audio_b64: toB64(new Uint8Array(i16.buffer))
        }));
        if ((++framesSent % 10) === 0) log('[mic] frames sent:', framesSent, 'len:', samples.length);
      } catch (err) { console.error('WS send failed', err); }
    }
  };

  micSink = audioCtx.createGain(); micSink.gain.value = 0;
  srcNode.connect(micNodeLocal); micNodeLocal.connect(micSink); micSink.connect(audioCtx.destination);

  micNode = micNodeLocal;

  $('start').disabled = true; $('stop').disabled = false;
  setStatus("Listeningâ€¦","listen");
}

async function stop(){
  running=false;

  // finalize anything pending + stop TTS
  try { ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"flush"})); } catch {}
  try { ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:"barge_in"})); } catch {}
  ttsStopLocal();

  // small window for 'final' to land
  try { await new Promise(r => setTimeout(r, 200)); } catch {}

  try{ micNode && micNode.disconnect(); }catch{}
  try{ micSink && micSink.disconnect(); }catch{}
  try{ stream && stream.getTracks().forEach(t=>t.stop()); }catch{}
  try{ audioCtx && audioCtx.close(); }catch{}
  try{ ws && ws.close(); }catch{}
  if (pingTimer) { clearInterval(pingTimer); pingTimer=null; }
  micNode=null; micSink=null; stream=null; audioCtx=null;
  $('start').disabled = false; $('stop').disabled = true;
  setStatus("Stopped.");
}

/* =========================
   Echo + controls
========================= */
$('echo').onclick = ()=>{
  const t = new WebSocket(ECHO_URL);
  t.onopen  = ()=>console.log('[ECHO] open');
  t.onerror = (e)=>console.error('[ECHO] error', e);
  t.onclose = (e)=>console.warn('[ECHO] close', e.code, e.reason);
  t.onmessage=(e)=>console.log('[ECHO] msg', e.data);
  setTimeout(()=>{ try{ t.readyState===WebSocket.OPEN && t.send('hello'); }catch{} }, 500);
};
$('force').onclick = ()=>{ try{ ws && ws.readyState===WebSocket.OPEN && ws.send(JSON.stringify({type:'flush'})); }catch{} };
$('start').onclick = start;
$('stop').onclick  = stop;
window.addEventListener('beforeunload', ()=>{ try{ ws && ws.close(); }catch{} });
</script>
</body>
</html>
