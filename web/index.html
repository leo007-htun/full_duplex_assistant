<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.11/dist/bundle.min.js"></script>
</head>
<body class="bg-gray-900 text-white flex flex-col items-center justify-center min-h-screen">
  <div class="bg-gray-800 p-6 rounded-2xl shadow-lg w-full max-w-lg text-center">
    <h1 class="text-2xl font-bold mb-4">🎙️ Browser Voice Assistant</h1>
    <button id="startBtn" class="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-lg">
      Start Talking
    </button>
    <div class="mt-6">
      <h2 class="text-lg font-semibold">Transcript</h2>
      <p id="transcript" class="bg-gray-700 p-3 rounded mt-2"></p>
    </div>
    <div class="mt-6">
      <h2 class="text-lg font-semibold">Assistant Response</h2>
      <p id="response" class="bg-gray-700 p-3 rounded mt-2"></p>
    </div>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let currentAudio = null;

    function stopTTS() {
      if (currentAudio) {
        currentAudio.pause();
        currentAudio = null;
      }
    }

    async function setupVAD(stream) {
      const vadInstance = await window.vad.MicVAD.new({
        stream,
        onSpeechStart: () => {
          console.log("🎙️ User speaking → stop TTS");
          stopTTS();
        }
      });
      vadInstance.start();
    }

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setupVAD(stream);

      mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("file", blob, "input.webm");

        const resp = await fetch("/api/transcribe", { method: "POST", body: formData });
        const data = await resp.json();
        document.getElementById("transcript").innerText = data.text;

        const intentResp = await fetch("/api/determine_intent", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: data.text })
        });
        const intentData = await intentResp.json();
        document.getElementById("response").innerText = intentData.result;

        const ttsResp = await fetch("/api/tts", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: intentData.result })
        });
        const audioBlob = await ttsResp.blob();
        currentAudio = new Audio(URL.createObjectURL(audioBlob));
        currentAudio.play();
      };

      mediaRecorder.start();
      setTimeout(() => mediaRecorder.stop(), 5000); // record 5s at a time
    }

    document.getElementById("startBtn").addEventListener("click", startRecording);
  </script>
</body>
</html>
